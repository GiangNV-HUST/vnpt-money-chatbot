{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 14119706,
     "sourceType": "datasetVersion",
     "datasetId": 8995276
    }
   ],
   "dockerImageVersionId": 31193,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# VNPT MONEY FAQ - FINE-TUNING NOTEBOOK\n# =====================================\n# \n# Notebook n√†y s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ paraphrase_documents_clean.json ƒë·ªÉ fine-tune model Vietnamese SBERT\n# v·ªõi ph∆∞∆°ng ph√°p MNRL (Multiple Negatives Ranking Loss)\n#\n# C√ÅCH S·ª¨ D·ª§NG:\n# 1. Ch·∫°y cell install dependencies\n# 2. Ch·∫°y cell ki·ªÉm tra file\n# 3. Ch·∫°y cell test parsing\n# 4. Ch·∫°y cell t·∫°o fine-tuning script\n# 5. Ch·∫°y cell fine-tuning\n#\n# Y√äU C·∫¶U:\n# - GPU (T4 ho·∫∑c P100)\n# - Dataset v·ªõi file paraphrase_documents_clean.json\n#\n# K·∫æT QU·∫¢:\n# - Model s·∫Ω ƒë∆∞·ª£c l∆∞u trong /kaggle/working/models/vnpt-sbert-mnrl/\n\nprint(\"üìò VNPT Money FAQ Fine-tuning Notebook\")\nprint(\"=\" * 50)\nprint(\"‚úÖ S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´: /data/paraphrase_documents_clean.json\")\nprint(\"‚úÖ Base model: keepitreal/vietnamese-sbert\")\nprint(\"‚úÖ Method: MNRL (Multiple Negatives Ranking Loss)\")\nprint(\"=\" * 50)",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-12T03:45:30.410061Z",
     "iopub.execute_input": "2025-12-12T03:45:30.410675Z",
     "iopub.status.idle": "2025-12-12T03:45:30.415804Z",
     "shell.execute_reply.started": "2025-12-12T03:45:30.410654Z",
     "shell.execute_reply": "2025-12-12T03:45:30.414921Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "%%time\n# Install required packages v·ªõi phi√™n b·∫£n t∆∞∆°ng th√≠ch\n!pip install -q sentence-transformers==2.2.2 torch transformers\n\nprint(\"‚úÖ Packages installed!\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-12T03:45:30.417079Z",
     "iopub.execute_input": "2025-12-12T03:45:30.417440Z",
     "iopub.status.idle": "2025-12-12T03:46:45.028987Z",
     "shell.execute_reply.started": "2025-12-12T03:45:30.417424Z",
     "shell.execute_reply": "2025-12-12T03:46:45.028259Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Ki·ªÉm tra file paraphrase_documents_clean.json t·ª´ Kaggle dataset\nimport os\nimport json\n\n# ƒê∆∞·ªùng d·∫´n tr√™n Kaggle\njson_file = \"/kaggle/input/vnpt-money-faq-data/paraphrase_documents_clean.json\"\n\nif os.path.exists(json_file):\n    file_size = os.path.getsize(json_file) / 1024  # KB\n    print(f\"‚úÖ Found {json_file}\")\n    print(f\"   Size: {file_size:.1f} KB\")\n    \n    # ƒê·ªçc v√† hi·ªÉn th·ªã th√¥ng tin v·ªÅ d·ªØ li·ªáu\n    with open(json_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    print(f\"   Total documents: {len(data)}\")\n    print(f\"\\nüìã Sample document:\")\n    if len(data) > 0:\n        sample = data[0]\n        print(f\"   Question: {sample['metadata']['question'][:80]}...\")\n        print(f\"   Answer: {sample['metadata']['answer'][:80]}...\")\n        print(f\"   Section: {sample['metadata'].get('section', 'N/A')}\")\n        print(f\"   Source: {sample['metadata'].get('source', 'N/A')}\")\nelse:\n    print(f\"‚ùå File not found: {json_file}\")\n    print(\"   Please make sure you added the dataset with paraphrase_documents_clean.json\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-12T03:46:45.029951Z",
     "iopub.execute_input": "2025-12-12T03:46:45.030186Z",
     "iopub.status.idle": "2025-12-12T03:46:45.040787Z",
     "shell.execute_reply.started": "2025-12-12T03:46:45.030162Z",
     "shell.execute_reply": "2025-12-12T03:46:45.040213Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Test parsing paraphrase_documents_clean.json\nimport json\nfrom typing import List, Dict\n\ndef parse_documents_from_json(file_path: str) -> List[Dict]:\n    \"\"\"Parse documents t·ª´ file paraphrase_documents_clean.json\"\"\"\n    print(f\"üìÇ Reading documents from: {file_path}\")\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    print(f\"   Total entries: {len(data)}\")\n    \n    documents = []\n    \n    for idx, item in enumerate(data, 1):\n        try:\n            metadata = item.get('metadata', {})\n            \n            question = metadata.get('question', '').strip()\n            answer = metadata.get('answer', '').strip()\n            \n            if not question or not answer:\n                continue\n            \n            doc_data = {\n                'question': question,\n                'answer': answer,\n                'section': metadata.get('section', ''),\n                'sheet_name': metadata.get('sheet_name', ''),\n                'source': metadata.get('source', ''),\n                'type': metadata.get('type', ''),\n            }\n            \n            documents.append(doc_data)\n            \n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error parsing document {idx}: {e}\")\n            continue\n    \n    print(f\"‚úÖ Successfully parsed {len(documents)} documents\\n\")\n    return documents\n\n# Test v·ªõi file t·ª´ Kaggle dataset\njson_file = \"/kaggle/input/vnpt-money-faq-data/paraphrase_documents_clean.json\"\ndocuments = parse_documents_from_json(json_file)\n\nprint(f\"Total documents loaded: {len(documents)}\\n\")\n\n# Show first 3 documents\nfor i in range(min(3, len(documents))):\n    print(f\"Document {i+1}:\")\n    print(f\"  Q: {documents[i]['question'][:60]}...\")\n    print(f\"  A: {documents[i]['answer'][:60]}...\")\n    print(f\"  Section: {documents[i]['section']}\")\n    print(f\"  Sheet: {documents[i]['sheet_name']}\")\n    print()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-12T03:46:45.042212Z",
     "iopub.execute_input": "2025-12-12T03:46:45.042408Z",
     "iopub.status.idle": "2025-12-12T03:46:45.075347Z",
     "shell.execute_reply.started": "2025-12-12T03:46:45.042388Z",
     "shell.execute_reply": "2025-12-12T03:46:45.074796Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "%%writefile finetune_mnrl_kaggle.py\n\"\"\"\nFine-tune v·ªõi MNRL tr√™n Kaggle GPU\n\"\"\"\nimport logging\nfrom sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\nfrom torch.utils.data import DataLoader\nfrom typing import List, Dict, Tuple\nimport os\nimport json\nimport random\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nlogging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')\nlogger = logging.getLogger(__name__)\n\n\ndef parse_documents_from_json(file_path: str) -> List[Dict]:\n    \"\"\"Parse documents t·ª´ file paraphrase_documents_clean.json\"\"\"\n    logger.info(f\"üìÇ Reading documents from: {file_path}\")\n    \n    if not os.path.exists(file_path):\n        logger.error(f\"‚ùå File not found: {file_path}\")\n        return []\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    logger.info(f\"   Total entries: {len(data)}\")\n    \n    documents = []\n    \n    for idx, item in enumerate(data, 1):\n        try:\n            metadata = item.get('metadata', {})\n            \n            question = metadata.get('question', '').strip()\n            answer = metadata.get('answer', '').strip()\n            \n            if not question or not answer:\n                continue\n            \n            doc_data = {\n                'question': question,\n                'answer': answer,\n                'section': metadata.get('section', ''),\n                'sheet_name': metadata.get('sheet_name', ''),\n                'source': metadata.get('source', ''),\n                'type': metadata.get('type', ''),\n            }\n            \n            documents.append(doc_data)\n            \n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è Error parsing document {idx}: {e}\")\n            continue\n    \n    logger.info(f\"‚úÖ Successfully parsed {len(documents)} documents\")\n    return documents\n\n\nclass MNRLFineTuner:\n    def __init__(\n        self,\n        base_model: str = \"keepitreal/vietnamese-sbert\",\n        output_path: str = \"vnpt-sbert-mnrl\",\n    ):\n        self.base_model = base_model\n        self.output_path = output_path\n\n        logger.info(f\"Loading base model: {base_model}\")\n        self.model = SentenceTransformer(base_model)\n\n        import torch\n        if torch.cuda.is_available():\n            logger.info(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n            logger.info(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n        else:\n            logger.warning(\"‚ö†Ô∏è No GPU detected, using CPU\")\n\n    def prepare_training_data(\n        self, \n        documents: List[Dict],\n        validation_split: float = 0.15\n    ) -> Tuple[List[InputExample], List[InputExample]]:\n        \"\"\"\n        Prepare training and validation data with split\n        \"\"\"\n        logger.info(f\"\\nPreparing MNRL training data from {len(documents)} documents...\")\n        logger.info(f\"Validation split: {validation_split * 100:.0f}%\")\n\n        # Shuffle documents\n        random.seed(42)\n        shuffled_docs = documents.copy()\n        random.shuffle(shuffled_docs)\n        \n        # Calculate split\n        split_idx = int(len(shuffled_docs) * (1 - validation_split))\n        train_docs = shuffled_docs[:split_idx]\n        val_docs = shuffled_docs[split_idx:]\n        \n        logger.info(f\"   Train: {len(train_docs)} documents\")\n        logger.info(f\"   Validation: {len(val_docs)} documents\")\n\n        # Create training examples\n        training_examples = []\n        for doc in train_docs:\n            question = doc['question'].strip()\n            answer = doc['answer'].strip()\n            if question and answer:\n                example = InputExample(texts=[question, answer])\n                training_examples.append(example)\n\n        # Create validation examples\n        validation_examples = []\n        for doc in val_docs:\n            question = doc['question'].strip()\n            answer = doc['answer'].strip()\n            if question and answer:\n                example = InputExample(texts=[question, answer])\n                validation_examples.append(example)\n\n        logger.info(f\"‚úÖ Created {len(training_examples)} training examples\")\n        logger.info(f\"‚úÖ Created {len(validation_examples)} validation examples\\n\")\n        \n        return training_examples, validation_examples\n\n    def fine_tune(\n        self,\n        training_examples: List[InputExample],\n        validation_examples: List[InputExample] = None,\n        epochs: int = 6,\n        batch_size: int = 32,\n        learning_rate: float = 2e-5,\n        warmup_steps: int = None,\n    ):\n        \"\"\"\n        Fine-tune model with optimized parameters\n        \"\"\"\n        # Auto-calculate warmup steps if not provided\n        if warmup_steps is None:\n            steps_per_epoch = len(training_examples) // batch_size\n            total_steps = steps_per_epoch * epochs\n            warmup_steps = int(total_steps * 0.1)  # 10% of total steps\n        \n        logger.info(f\"{'='*60}\")\n        logger.info(f\"Starting MNRL fine-tuning\")\n        logger.info(f\"{'='*60}\")\n        logger.info(f\"Training examples: {len(training_examples)}\")\n        if validation_examples:\n            logger.info(f\"Validation examples: {len(validation_examples)}\")\n        logger.info(f\"Epochs: {epochs}\")\n        logger.info(f\"Batch size: {batch_size}\")\n        logger.info(f\"Learning rate: {learning_rate}\")\n        logger.info(f\"Warmup steps: {warmup_steps}\")\n        logger.info(f\"{'='*60}\\n\")\n\n        train_dataloader = DataLoader(\n            training_examples,\n            shuffle=True,\n            batch_size=batch_size\n        )\n\n        train_loss = losses.MultipleNegativesRankingLoss(\n            model=self.model,\n            scale=20.0\n        )\n\n        logger.info(\"Using MultipleNegativesRankingLoss (scale=20.0)\\n\")\n\n        # Setup evaluator if validation data is provided\n        evaluator = None\n        if validation_examples:\n            # Create evaluator for semantic similarity\n            sentences1 = [ex.texts[0] for ex in validation_examples]\n            sentences2 = [ex.texts[1] for ex in validation_examples]\n            scores = [1.0] * len(validation_examples)  # All pairs are semantically similar\n            \n            evaluator = evaluation.EmbeddingSimilarityEvaluator(\n                sentences1, \n                sentences2, \n                scores,\n                name='validation'\n            )\n            logger.info(\"‚úÖ Validation evaluator created\\n\")\n\n        # Fine-tune with optimizer parameters\n        self.model.fit(\n            train_objectives=[(train_dataloader, train_loss)],\n            epochs=epochs,\n            warmup_steps=warmup_steps,\n            optimizer_params={'lr': learning_rate},\n            evaluator=evaluator,\n            evaluation_steps=500,  # Evaluate every 500 steps\n            output_path=self.output_path,\n            save_best_model=True,\n            show_progress_bar=True,\n        )\n\n        logger.info(f\"\\n{'='*60}\")\n        logger.info(f\"‚úÖ Fine-tuning completed!\")\n        logger.info(f\"‚úÖ Model saved to: {self.output_path}\")\n        logger.info(f\"{'='*60}\\n\")\n\n\nif __name__ == \"__main__\":\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"VNPT MONEY FAQ - FINE-TUNING WITH MNRL\")\n    logger.info(\"=\"*60 + \"\\n\")\n    \n    # Load t·ª´ Kaggle dataset\n    json_file = \"/kaggle/input/vnpt-money-faq-data/paraphrase_documents_clean.json\"\n    \n    if not os.path.exists(json_file):\n        logger.error(f\"‚ùå File not found: {json_file}\")\n        exit(1)\n    \n    documents = parse_documents_from_json(json_file)\n\n    if not documents:\n        logger.error(\"‚ùå No documents found!\")\n        exit(1)\n\n    logger.info(f\"\\n‚úÖ Successfully loaded {len(documents)} documents\")\n    \n    if documents:\n        logger.info(\"\\nüìã Sample document:\")\n        logger.info(f\"   Q: {documents[0]['question'][:80]}...\")\n        logger.info(f\"   A: {documents[0]['answer'][:80]}...\")\n\n    finetuner = MNRLFineTuner(\n        base_model=\"keepitreal/vietnamese-sbert\",\n        output_path=\"/kaggle/working/vnpt-sbert-mnrl\",\n    )\n\n    # Prepare data with validation split\n    training_examples, validation_examples = finetuner.prepare_training_data(\n        documents,\n        validation_split=0.15  # 15% for validation\n    )\n    \n    if not training_examples:\n        logger.error(\"‚ùå No training examples created!\")\n        exit(1)\n\n    # Fine-tune v·ªõi tham s·ªë t·ªëi ∆∞u\n    finetuner.fine_tune(\n        training_examples=training_examples,\n        validation_examples=validation_examples,\n        epochs=6,              # TƒÉng t·ª´ 3 l√™n 6\n        batch_size=32,         # Gi·ªØ nguy√™n, ph√π h·ª£p GPU T4\n        learning_rate=2e-5,    # Th√™m learning rate\n        warmup_steps=None,     # Auto-calculate (10% total steps)\n    )\n\n    logger.info(\"=\"*60)\n    logger.info(\"‚úÖ ALL DONE!\")\n    logger.info(f\"Model saved to: /kaggle/working/vnpt-sbert-mnrl\")\n    logger.info(\"Download from Output tab ‚Üí\")\n    logger.info(\"=\"*60)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-12T03:46:45.076027Z",
     "iopub.execute_input": "2025-12-12T03:46:45.076301Z",
     "iopub.status.idle": "2025-12-12T03:46:45.083903Z",
     "shell.execute_reply.started": "2025-12-12T03:46:45.076283Z",
     "shell.execute_reply": "2025-12-12T03:46:45.083345Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Test model ngay tr√™n Kaggle tr∆∞·ªõc khi t·∫£i v·ªÅ\nfrom sentence_transformers import SentenceTransformer, util\n\nmodel_path = \"/kaggle/working/vnpt-sbert-mnrl\"\n\nprint(\"=\"*60)\nprint(\"TESTING FINE-TUNED MODEL\")\nprint(\"=\"*60)\n\n# Load model\nprint(f\"\\nüìÇ Loading model from: {model_path}\")\nmodel = SentenceTransformer(model_path)\nprint(\"‚úÖ Model loaded!\\n\")\n\n# Test queries\ntest_queries = [\n    \"L√†m sao ƒë·ªÉ n·∫°p ti·ªÅn v√†o VNPT Money?\",\n    \"T√¥i mu·ªën r√∫t ti·ªÅn v·ªÅ ng√¢n h√†ng\",\n    \"Ph√≠ chuy·ªÉn ti·ªÅn l√† bao nhi√™u?\",\n]\n\nprint(\"üß™ Testing v·ªõi m·ªôt s·ªë c√¢u h·ªèi m·∫´u:\")\nprint(\"-\" * 60)\n\nfor query in test_queries:\n    embedding = model.encode(query)\n    print(f\"\\nQuery: {query}\")\n    print(f\"Embedding shape: {embedding.shape}\")\n    print(f\"Sample values: {embedding[:5]}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Model ho·∫°t ƒë·ªông t·ªët!\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# B∆Ø·ªöC CU·ªêI: N√âN V√Ä T·∫¢I MODEL V·ªÄ M√ÅY\n# ========================================\n\nimport shutil\nimport os\n\nmodel_path = \"/kaggle/working/vnpt-sbert-mnrl\"\n\nprint(\"=\"*60)\nprint(\"üì¶ CHU·∫®N B·ªä T·∫¢I MODEL V·ªÄ M√ÅY LOCAL\")\nprint(\"=\"*60)\n\nif not os.path.exists(model_path):\n    print(f\"\\n‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i {model_path}\")\n    print(\"   H√£y ch·∫°y cell fine-tuning tr∆∞·ªõc!\\n\")\nelse:\n    # N√©n model th√†nh ZIP\n    print(f\"\\nüì¶ ƒêang n√©n model...\")\n    zip_name = \"vnpt-sbert-mnrl\"\n    \n    shutil.make_archive(\n        base_name=f\"/kaggle/working/{zip_name}\",\n        format='zip',\n        root_dir='/kaggle/working',\n        base_dir='vnpt-sbert-mnrl'\n    )\n    \n    zip_file = f\"/kaggle/working/{zip_name}.zip\"\n    size_mb = os.path.getsize(zip_file) / (1024 * 1024)\n    \n    print(f\"‚úÖ ƒê√£ n√©n xong!\")\n    print(f\"   File: {zip_file}\")\n    print(f\"   Size: {size_mb:.1f} MB\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"üíæ C√ÅCH T·∫¢I V·ªÄ M√ÅY:\")\n    print(\"=\"*60)\n    \n    print(\"\\nüìå C√ÅCH 1: T·∫£i t·ª´ Kaggle UI (KHUY·∫æN NGH·ªä)\")\n    print(\"-\" * 60)\n    print(\"   1. Click v√†o bi·ªÉu t∆∞·ª£ng ‚¨áÔ∏è 'Download' ·ªü g√≥c ph·∫£i tr√™n\")\n    print(\"   2. Ch·ªçn file 'vnpt-sbert-mnrl.zip'\")\n    print(\"   3. Gi·∫£i n√©n v·ªÅ th∆∞ m·ª•c project c·ªßa b·∫°n\")\n    \n    print(\"\\nüìå C√ÅCH 2: D√πng Kaggle API (T·ª± ƒë·ªông)\")\n    print(\"-\" * 60)\n    print(\"   Tr√™n m√°y local, ch·∫°y l·ªánh:\")\n    print(\"   \")\n    print(\"   pip install kaggle\")\n    print(f\"   kaggle kernels output <your-username>/vnpt-money-finetuning -p ./\")\n    print()\n    print(\"   (C·∫ßn setup kaggle.json token tr∆∞·ªõc)\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"‚úÖ S·∫¥N S√ÄNG T·∫¢I V·ªÄ!\")\n    print(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}