# LangChain Memory Integration Guide

## Tá»•ng quan

Há»‡ thá»‘ng GraphRAG Chatbot Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vá»›i **LangChain Memory** Ä‘á»ƒ quáº£n lÃ½ lá»‹ch sá»­ há»™i thoáº¡i má»™t cÃ¡ch thÃ´ng minh, tá»± Ä‘á»™ng tÃ³m táº¯t khi cuá»™c há»™i thoáº¡i quÃ¡ dÃ i.

## CÃ¡ch hoáº¡t Ä‘á»™ng

### 1. **ConversationSummaryBufferMemory** (Khuyáº¿n nghá»‹ - Äang sá»­ dá»¥ng)

ÄÃ¢y lÃ  cháº¿ Ä‘á»™ **hybrid** káº¿t há»£p giá»¯a:
- **Summary**: TÃ³m táº¯t cÃ¡c tin nháº¯n cÅ© Ä‘á»ƒ tiáº¿t kiá»‡m token
- **Buffer**: Giá»¯ nguyÃªn cÃ¡c tin nháº¯n gáº§n Ä‘Ã¢y Ä‘á»ƒ báº£o toÃ n chi tiáº¿t

**CÆ¡ cháº¿**:
1. Khi sá»‘ token vÆ°á»£t quÃ¡ `MEMORY_MAX_TOKEN_LIMIT` (máº·c Ä‘á»‹nh: 2000)
2. Há»‡ thá»‘ng tá»± Ä‘á»™ng gá»i LLM Ä‘á»ƒ tÃ³m táº¯t cÃ¡c tin nháº¯n cÅ© (trá»« 4 tin nháº¯n gáº§n nháº¥t)
3. Giá»¯ láº¡i summary + tin nháº¯n gáº§n Ä‘Ã¢y
4. Tiáº¿t kiá»‡m token nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c ngá»¯ cáº£nh quan trá»ng

### 2. **Buffer Mode** (TÃ¹y chá»n)

LÆ°u toÃ n bá»™ tin nháº¯n gá»‘c, khÃ´ng tÃ³m táº¯t.

**Æ¯u Ä‘iá»ƒm**:
- Giá»¯ nguyÃªn 100% thÃ´ng tin chi tiáº¿t
- KhÃ´ng cáº§n gá»i LLM Ä‘á»ƒ tÃ³m táº¯t

**NhÆ°á»£c Ä‘iá»ƒm**:
- Tá»‘n nhiá»u token khi há»™i thoáº¡i dÃ i
- CÃ³ giá»›i háº¡n Ä‘á»™ dÃ i (context window limit)

**PhÃ¹ há»£p**: Há»™i thoáº¡i ngáº¯n (< 10 lÆ°á»£t)

### 3. **Summary Only Mode** (TÃ¹y chá»n)

Chá»‰ lÆ°u tÃ³m táº¯t, khÃ´ng giá»¯ tin nháº¯n gá»‘c.

**Æ¯u Ä‘iá»ƒm**:
- Tiáº¿t kiá»‡m token tá»‘i Ä‘a
- KhÃ´ng giá»›i háº¡n Ä‘á»™ dÃ i há»™i thoáº¡i

**NhÆ°á»£c Ä‘iá»ƒm**:
- Máº¥t chi tiáº¿t cá»¥ thá»ƒ
- Má»—i láº§n cáº­p nháº­t pháº£i gá»i LLM (chi phÃ­ + Ä‘á»™ trá»…)

**PhÃ¹ há»£p**: Há»™i thoáº¡i ráº¥t dÃ i, chá»‰ cáº§n ngá»¯ cáº£nh chung

## Cáº¥u hÃ¬nh

### File `config.py`

```python
# Conversation Memory Configuration (LangChain)
ENABLE_LANGCHAIN_MEMORY = True  # Báº­t/táº¯t LangChain Memory
MEMORY_TYPE = "summary_buffer"  # Options: "buffer", "summary", "summary_buffer"
MEMORY_MAX_TOKEN_LIMIT = 2000   # Max tokens trÆ°á»›c khi tÃ³m táº¯t
MEMORY_RETURN_MESSAGES = True   # Return as message objects
MEMORY_AI_PREFIX = "VNPT Assistant"
MEMORY_HUMAN_PREFIX = "KhÃ¡ch hÃ ng"
```

### Thay Ä‘á»•i cháº¿ Ä‘á»™ Memory

**Äá»ƒ sá»­ dá»¥ng Buffer Mode** (giá»¯ toÃ n bá»™ tin nháº¯n):
```python
MEMORY_TYPE = "buffer"
```

**Äá»ƒ sá»­ dá»¥ng Summary Only**:
```python
MEMORY_TYPE = "summary"
```

**Äá»ƒ sá»­ dá»¥ng Summary Buffer** (khuyáº¿n nghá»‹):
```python
MEMORY_TYPE = "summary_buffer"
MEMORY_MAX_TOKEN_LIMIT = 2000  # Äiá»u chá»‰nh Ä‘á»ƒ kiá»ƒm soÃ¡t khi nÃ o tÃ³m táº¯t
```

## Sá»­ dá»¥ng trong Code

### Khá»Ÿi táº¡o

```python
from conversation_context_manager import ConversationContextManager

# Sá»­ dá»¥ng cáº¥u hÃ¬nh tá»« config.py
manager = ConversationContextManager(max_history=10)

# Hoáº·c override cáº¥u hÃ¬nh
manager = ConversationContextManager(
    max_history=10,
    enable_langchain_memory=True
)
```

### ThÃªm cuá»™c há»™i thoáº¡i

```python
# ThÃªm má»™t lÆ°á»£t há»™i thoáº¡i
manager.add_turn(
    user_query="LÃ m sao Ä‘á»ƒ rÃºt tiá»n?",
    bot_response={
        "answer": "Äá»ƒ rÃºt tiá»n: BÆ°á»›c 1...",
        "related_entities": {...}
    }
)
```

### Láº¥y lá»‹ch sá»­ há»™i thoáº¡i

```python
# Láº¥y full history (bao gá»“m summary + tin nháº¯n gáº§n Ä‘Ã¢y)
history = manager.get_full_conversation_history()
print(history)

# Output:
# === TÃ“M Táº®T CUá»˜C Há»˜I THOáº I TRÆ¯á»šC ÄÃ“ ===
# KhÃ¡ch hÃ ng Ä‘Ã£ há»i vá» cÃ¡ch náº¡p tiá»n, rÃºt tiá»n...
#
# === CÃC TIN NHáº®N Gáº¦N ÄÃ‚Y ===
# ğŸ‘¤ KhÃ¡ch hÃ ng: OTP Ä‘Æ°á»£c gá»­i qua Ä‘Ã¢u?
# ğŸ¤– VNPT Assistant: OTP Ä‘Æ°á»£c gá»­i qua SMS...
```

### Láº¥y summary

```python
# Chá»‰ láº¥y pháº§n tÃ³m táº¯t
summary = manager.get_memory_summary()
print(summary)
```

### Kiá»ƒm tra thÃ´ng tin Memory

```python
# Láº¥y thá»‘ng kÃª
summary = manager.get_summary()
print(f"LangChain enabled: {summary['langchain_memory_enabled']}")
print(f"Memory type: {summary.get('memory_type')}")
print(f"Number of turns: {summary['num_turns']}")
```

### XÃ³a lá»‹ch sá»­

```python
# XÃ³a toÃ n bá»™ (bao gá»“m cáº£ LangChain memory)
manager.clear_context()
```

## VÃ­ dá»¥ thá»±c táº¿

### VÃ­ dá»¥ 1: Há»™i thoáº¡i ngáº¯n (khÃ´ng trigger summarization)

```python
manager = ConversationContextManager()

# Turn 1
manager.add_turn("LÃ m sao Ä‘á»ƒ rÃºt tiá»n?", {"answer": "BÆ°á»›c 1: ...", ...})

# Turn 2
manager.add_turn("Sau bÆ°á»›c 1 thÃ¬ sao?", {"answer": "BÆ°á»›c 2: ...", ...})

# Láº¥y history - váº«n giá»¯ nguyÃªn chi tiáº¿t
history = manager.get_full_conversation_history()
# â†’ Tráº£ vá» 2 turns Ä‘áº§y Ä‘á»§
```

### VÃ­ dá»¥ 2: Há»™i thoáº¡i dÃ i (trigger summarization)

```python
manager = ConversationContextManager()

# Giáº£ sá»­ cÃ³ 20 lÆ°á»£t há»™i thoáº¡i dÃ i
for i in range(20):
    manager.add_turn(
        f"CÃ¢u há»i {i}",
        {"answer": f"CÃ¢u tráº£ lá»i dÃ i {i}...", ...}
    )

# Khi vÆ°á»£t quÃ¡ MEMORY_MAX_TOKEN_LIMIT (2000 tokens)
# â†’ Tá»± Ä‘á»™ng tÃ³m táº¯t cÃ¡c tin nháº¯n cÅ©

# Láº¥y summary
summary = manager.get_memory_summary()
# â†’ Tráº£ vá» tÃ³m táº¯t cÃ¡c tin nháº¯n cÅ© + 4 tin nháº¯n gáº§n nháº¥t
```

## Test vÃ  Demo

Cháº¡y test script Ä‘á»ƒ xem LangChain Memory hoáº¡t Ä‘á»™ng:

```bash
cd GraphRAG
python test_langchain_memory.py
```

Test script sáº½ demo:
1. **Test 1**: Há»™i thoáº¡i cÆ¡ báº£n (3 turns)
2. **Test 2**: Há»™i thoáº¡i dÃ i (10 turns) - xem summarization
3. **Test 3**: So sÃ¡nh cÃ¡c cháº¿ Ä‘á»™ Memory

## Lá»£i Ã­ch

### 1. **Tiáº¿t kiá»‡m Token**
- Há»™i thoáº¡i dÃ i khÃ´ng cÃ²n tá»‘n quÃ¡ nhiá»u token
- Giáº£m chi phÃ­ API calls

### 2. **KhÃ´ng giá»›i háº¡n Ä‘á»™ dÃ i**
- CÃ³ thá»ƒ há»™i thoáº¡i liÃªn tá»¥c khÃ´ng lo vÆ°á»£t context limit
- PhÃ¹ há»£p cho chatbot customer service

### 3. **Giá»¯ ngá»¯ cáº£nh quan trá»ng**
- Summary buffer giá»¯ láº¡i chi tiáº¿t cá»§a tin nháº¯n gáº§n Ä‘Ã¢y
- Váº«n cÃ³ overview cá»§a toÃ n bá»™ cuá»™c há»™i thoáº¡i

### 4. **Tá»± Ä‘á»™ng hÃ³a**
- KhÃ´ng cáº§n quáº£n lÃ½ manual viá»‡c cáº¯t bá» tin nháº¯n cÅ©
- LLM tá»± Ä‘á»™ng tÃ³m táº¯t thÃ´ng minh

## LÆ°u Ã½

### YÃªu cáº§u
- Cáº§n cÃ³ `OPENAI_API_KEY` trong file `.env`
- Cáº§n cÃ i Ä‘áº·t: `pip install langchain langchain-openai langchain-community`

### Chi phÃ­
- Cháº¿ Ä‘á»™ `summary_buffer` sáº½ gá»i LLM Ä‘á»ƒ tÃ³m táº¯t khi cáº§n
- Chi phÃ­ phá»¥ thuá»™c vÃ o:
  - Sá»‘ láº§n summarize
  - Model sá»­ dá»¥ng (máº·c Ä‘á»‹nh: gpt-4o-mini - ráº»)
  - Äá»™ dÃ i tin nháº¯n cáº§n tÃ³m táº¯t

### Performance
- Summarization tá»‘n thá»i gian (gá»i LLM)
- NÃªn Ä‘iá»u chá»‰nh `MEMORY_MAX_TOKEN_LIMIT` há»£p lÃ½:
  - QuÃ¡ tháº¥p (< 1000): TÃ³m táº¯t quÃ¡ thÆ°á»ng xuyÃªn
  - QuÃ¡ cao (> 5000): Ãt tÃ³m táº¯t, tá»‘n token

## Troubleshooting

### LangChain khÃ´ng kháº£ dá»¥ng
Náº¿u tháº¥y warning: "LangChain not available"
```bash
pip install langchain langchain-openai langchain-community
```

### Lá»—i OpenAI API Key
Äáº£m báº£o cÃ³ file `.env` vá»›i:
```
OPENAI_API_KEY=sk-...
```

### Disable LangChain Memory
Trong `config.py`:
```python
ENABLE_LANGCHAIN_MEMORY = False
```

## TÃ­ch há»£p vá»›i Chatbot

LangChain Memory Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o [chatbot.py](chatbot.py:27) vÃ  hoáº¡t Ä‘á»™ng tá»± Ä‘á»™ng:

```python
# Trong GraphRAGChatbot.__init__()
self.context_manager = ConversationContextManager(max_history=5)
# â†’ Tá»± Ä‘á»™ng sá»­ dá»¥ng LangChain memory náº¿u ENABLE_LANGCHAIN_MEMORY=True

# Má»—i láº§n chat
response = chatbot.chat("LÃ m sao Ä‘á»ƒ rÃºt tiá»n?")
# â†’ Tá»± Ä‘á»™ng lÆ°u vÃ o LangChain memory
# â†’ Tá»± Ä‘á»™ng tÃ³m táº¯t náº¿u cáº§n
```

## Káº¿t luáº­n

LangChain Memory giÃºp chatbot:
- âœ… Quáº£n lÃ½ há»™i thoáº¡i dÃ i hiá»‡u quáº£
- âœ… Tiáº¿t kiá»‡m token vÃ  chi phÃ­
- âœ… Giá»¯ ngá»¯ cáº£nh quan trá»ng
- âœ… Hoáº¡t Ä‘á»™ng tá»± Ä‘á»™ng, khÃ´ng cáº§n can thiá»‡p

**Khuyáº¿n nghá»‹**: Sá»­ dá»¥ng cháº¿ Ä‘á»™ `summary_buffer` vá»›i `MEMORY_MAX_TOKEN_LIMIT=2000` cho háº§u háº¿t cÃ¡c use case.
